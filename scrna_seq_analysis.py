# -*- coding: utf-8 -*-
"""scRNA_Seq_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iu5pOJ-yegNhavEFefiG4J7NERkHo_yU

## Importing required libraries
"""

!pip install anndata
!pip install scanpy

import anndata as ad
import scanpy as sc
import pandas as pd
from scipy.io import mmread
from scipy.sparse import csr_matrix
import seaborn as sns

"""## Problem 1: Ingesting and Labeling Public scRNA-seq Datasets

## Task 1: Ingest datasets into AnnData format
"""

# GSE142541 Dataset (Control)
genes_ctrl = pd.read_csv('/content/GSE142541_mouse_features.tsv', sep='\t', header=None)
genes_ctrl.columns = ['id', 'name', 'o']
genes_ctrl['name'] = genes_ctrl['name'].astype(str)
genes_ctrl['name'] = genes_ctrl['name'] + '_' + genes_ctrl.groupby('name').cumcount().astype(str)  # Ensure unique names

mtx_ctrl = mmread('/content/matrix.mtx').T  # Read matrix and transpose
mtx_ctrl = csr_matrix(mtx_ctrl)

barcodes_ctrl = pd.read_csv('/content/GSE142541_mouse_barcodes.tsv', header=None)
barcodes_ctrl.columns = ['barcode']

adata_ctrl = ad.AnnData(X=mtx_ctrl)
adata_ctrl.var_names = genes_ctrl['name'].tolist()  # Set gene names
adata_ctrl.obs_names = barcodes_ctrl['barcode'].tolist()  # Set barcodes as observation names
adata_ctrl.var_names_make_unique()

# GSE180498 Dataset (Diseased)
file_path_diseased = '/content/GSE180498_gw_integrated_counts.csv'
data_diseased = pd.read_csv(file_path_diseased, index_col=0)

genes_diseased = data_diseased.index.tolist()
barcodes_diseased = data_diseased.columns.tolist()

mtx_diseased = csr_matrix(data_diseased.values).T

adata_diseased = ad.AnnData(X=mtx_diseased)
adata_diseased.var_names = genes_diseased
adata_diseased.obs_names = barcodes_diseased
adata_diseased.var_names_make_unique()

"""## Task 2: Label the samples"""

# Filter barcodes up to '-6'
filtered_barcodes = [bc for bc in adata_ctrl.obs_names if bc.endswith(('-1', '-2', '-3', '-4', '-5', '-6'))]
adata_ctrl = adata_ctrl[filtered_barcodes, :]

# Create sample mapping for each barcode suffix
sample_mapping_ctrl = {
    '-1': 'SC1',
    '-2': 'SC3',
    '-3': 'SC4',
    '-4': 'NOD-ctrl1',
    '-5': 'NOD-ctrl2-1',
    '-6': 'NOD-ctrl2-2',
}

# Create cohort mapping for groups
cohort_mapping_ctrl = {
    '-1': 'SC',
    '-2': 'SC',
    '-3': 'SC',
    '-4': 'NODCTRL',
    '-5': 'NODCTRL',
    '-6': 'NODCTRL',
}

# Add 'sample' and 'cohort' columns to adata_ctrl.obs
adata_ctrl.obs['sample'] = adata_ctrl.obs_names.str[-2:].map(sample_mapping_ctrl)
adata_ctrl.obs['cohort'] = adata_ctrl.obs_names.str[-2:].map(cohort_mapping_ctrl)

print(adata_ctrl.obs["sample"].value_counts())
adata_ctrl

# Check the result
print(adata_ctrl.obs.head())

# Create sample mapping for prefixes
sample_mapping_diseased = {
    'R1_': 'NOD.GW_SN_S1',
    'R2_': 'NOD.GW_SN_S2',
    'R3_': 'NOD.GW_SN_S3',
}

# All samples belong to the NODAIRE cohort
cohort_name_diseased = 'NODAIRE'

# Add 'sample' and 'cohort' columns to adata_diseased.obs
adata_diseased.obs['sample'] = adata_diseased.obs_names.str[:3].map(sample_mapping_diseased)
adata_diseased.obs['cohort'] = cohort_name_diseased

print(adata_diseased.obs["sample"].value_counts())
adata_diseased

# Check the result
print(adata_diseased.obs.head())

"""## Problem 2: Visual Inspection and Quality Control (QC) of scRNA-seq Data

## Task 1: Calculate QC Metrics for both datasets
"""

# For GSE142541 (Control dataset)
adata_ctrl.obs['total_counts'] = adata_ctrl.X.sum(axis=1).A1  # Sum of counts per gene
adata_ctrl.obs['n_genes'] = (adata_ctrl.X > 0).sum(axis=1).A1  # Count non-zero genes per gene
mito_genes_ctrl = [gene for gene in adata_ctrl.var_names if 'mt-' in gene]  # Mitochondrial genes
adata_ctrl.obs['mito_percent'] = adata_ctrl[:, mito_genes_ctrl].X.sum(axis=1).A1 / adata_ctrl.obs['total_counts'] * 100
print(adata_ctrl.obs.head())

# For GSE180498 (Diseased dataset)
adata_diseased.obs['total_counts'] = adata_diseased.X.sum(axis=1).A1  # Sum of counts per cell
adata_diseased.obs['n_genes'] = (adata_diseased.X > 0).sum(axis=1).A1  # Count non-zero genes per cell
mito_genes_diseased = [gene for gene in adata_diseased.var_names if 'mt-' in gene]  # Mitochondrial genes
adata_diseased.obs['mito_percent'] = adata_diseased[:, mito_genes_diseased].X.sum(axis=1).A1 / adata_diseased.obs['total_counts'] * 100
print(adata_diseased.obs.head())

"""## Task 2: Visual Inspection"""

# Set up the plot style
sns.set(style="whitegrid")

# Plot the distribution of QC metrics for GSE142541 (Control dataset)
sc.pl.violin(
    adata_ctrl,
    ["n_genes", "total_counts", "mito_percent"],
    jitter=0.4,
    multi_panel=True,
)

# Plot the distribution of QC metrics for GSE180498 (Diseased dataset)
sc.pl.violin(
    adata_diseased,
    ["n_genes", "total_counts", "mito_percent"],
    jitter=0.4,
    multi_panel=True,
)

# # Using Scanpy functions
# # mitochondrial genes, "MT-" for human, "Mt-" for mouse
# adata_ctrl.var["mt"] = adata_ctrl.var_names.str.startswith("mt-")
# # ribosomal genes
# adata_ctrl.var["ribo"] = adata_ctrl.var_names.str.startswith(("RPS", "RPL"))
# # hemoglobin genes
# adata_ctrl.var["hb"] = adata_ctrl.var_names.str.contains("^HB[^(P)]")

# sc.pp.calculate_qc_metrics(
#     adata_ctrl, qc_vars=["mt", "ribo", "hb"], inplace=True, log1p=True
# )

# sc.pl.violin(
#     adata_ctrl,
#     ["n_genes_by_counts", "total_counts", "pct_counts_mt"],
#     jitter=0.4,
#     multi_panel=True,
# )

# # Using Scanpy functions
# # mitochondrial genes, "MT-" for human, "Mt-" for mouse
# adata_diseased.var["mt"] = adata_diseased.var_names.str.startswith("mt-")
# # ribosomal genes
# adata_diseased.var["ribo"] = adata_diseased.var_names.str.startswith(("RPS", "RPL"))
# # hemoglobin genes
# adata_diseased.var["hb"] = adata_diseased.var_names.str.contains("^HB[^(P)]")

# sc.pp.calculate_qc_metrics(
#     adata_diseased, qc_vars=["mt", "ribo", "hb"], inplace=True, log1p=True
# )

# sc.pl.violin(
#     adata_diseased,
#     ["n_genes_by_counts", "total_counts", "pct_counts_mt"],
#     jitter=0.4,
#     multi_panel=True,
# )

# Inspecting scatter plots by joining all QC metrics
sc.pl.scatter(adata_ctrl, "total_counts", "n_genes", color="mito_percent")
sc.pl.scatter(adata_diseased, "total_counts", "n_genes", color="mito_percent")

"""## Data filtration"""

# sc.pp.filter_cells(adata_ctrl, min_genes=100)
# sc.pp.filter_genes(adata_ctrl, min_cells=3)

# sc.pp.filter_cells(adata_diseased, min_genes=100)
# sc.pp.filter_genes(adata_diseased, min_cells=3)

# GSE142541 (Control dataset filtering)
adata_ctrl = adata_ctrl[adata_ctrl.obs['n_genes'] > 200]  # Keep cells with >200 genes
adata_ctrl = adata_ctrl[adata_ctrl.obs['mito_percent'] < 15]  # Keep cells with <15% mitochondrial genes

# GSE180498 (Diseased dataset filtering)
adata_diseased = adata_diseased[adata_diseased.obs['n_genes'] > 200]  # Keep cells with >200 genes
adata_diseased = adata_diseased[adata_diseased.obs['mito_percent'] < 15]  # Keep cells with <15% mitochondrial genes

# Save filtered AnnData objects
# ctrl_data.write('/content/GSE142541_mouse_filtered.h5ad')
# diseased_data.write('/content/GSE180498_gw_filtered.h5ad')

"""## Doublet Finding"""

sc.pp.scrublet(adata_ctrl, batch_key="sample")
sc.pp.scrublet(adata_diseased, batch_key="sample")

print(adata_ctrl.obs.head())

print(adata_diseased.obs.head())

"""## Problem 3: Code Exploration and Statistical Analysis of sc.tl.rank_gene_groups

## 1) Code Exploration
"""

# Importing necessary libraries

from __future__ import annotations

from math import floor
from typing import TYPE_CHECKING, Literal

import numpy as np
import pandas as pd
from scipy.sparse import issparse, vstack

from .. import _utils
from .. import logging as logg
from .._compat import old_positionals
from .._utils import (
    check_nonnegative_integers,
    get_literal_vals,
    raise_not_implemented_error_if_backed_type,
)
from ..get import _check_mask
from ..preprocessing._utils import _get_mean_var

if TYPE_CHECKING:
    from collections.abc import Generator, Iterable

    from anndata import AnnData
    from numpy.typing import NDArray
    from scipy import sparse

    _CorrMethod = Literal["benjamini-hochberg", "bonferroni"]

# Used with get_literal_vals
_Method = Literal["logreg", "t-test", "wilcoxon", "t-test_overestim_var"]

def rank_genes_groups(
    adata: AnnData,
    groupby: str,
    *,
    mask_var: NDArray[np.bool_] | str | None = None,
    use_raw: bool | None = None,
    groups: Literal["all"] | Iterable[str] = "all",
    reference: str = "rest",
    n_genes: int | None = None,
    rankby_abs: bool = False,
    pts: bool = False,
    key_added: str | None = None,
    copy: bool = False,
    method: _Method | None = None,
    corr_method: _CorrMethod = "benjamini-hochberg",
    tie_correct: bool = False,
    layer: str | None = None,
    **kwds,
) -> AnnData | None:
    # Apply mask to filter variables if provided
    if mask_var is not None:
        mask_var = _check_mask(adata, mask_var, "var")

    # Decide whether to use `.raw` based on input and availability
    if use_raw is None:
        use_raw = adata.raw is not None
    elif use_raw is True and adata.raw is None:
        raise ValueError("Received `use_raw=True`, but `adata.raw` is empty.")

    # Default statistical method is t-test
    if method is None:
        method = "t-test"

    # Handle deprecated `only_positive` keyword for backwards compatibility
    if "only_positive" in kwds:
        rankby_abs = not kwds.pop("only_positive")

    # Log the start of the gene ranking process
    start = logg.info("ranking genes")

    # Validate the method and ensure it's supported
    if method not in (avail_methods := get_literal_vals(_Method)):                    # method validation
        raise ValueError(f"Method must be one of {avail_methods}.")

    # Validate the p-value correction method
    avail_corr = {"benjamini-hochberg", "bonferroni"}
    if corr_method not in avail_corr:
        raise ValueError(f"Correction method must be one of {avail_corr}.")

    # Create a copy of the `adata` object if `copy` is True
    adata = adata.copy() if copy else adata
    _utils.sanitize_anndata(adata)  # Clean up and standardize `adata`

    # Parse and validate the `groups` parameter
    if groups == "all":
        groups_order = "all"
    elif isinstance(groups, str | int):  # Ensure `groups` is a sequence
        raise ValueError("Specify a sequence of groups")
    else:
        groups_order = list(groups)
        # Convert integer group names to strings
        if isinstance(groups_order[0], int):
            groups_order = [str(n) for n in groups_order]
        # Ensure the reference group is included
        if reference != "rest" and reference not in set(groups_order):
            groups_order += [reference]

    # Validate that the reference group exists in `adata.obs[groupby]`
    if reference != "rest" and reference not in adata.obs[groupby].cat.categories:
        cats = adata.obs[groupby].cat.categories.tolist()
        raise ValueError(
            f"reference = {reference} needs to be one of groupby = {cats}."
        )

    # Initialize storage in `.uns` for results
    if key_added is None:
        key_added = "rank_genes_groups"
    adata.uns[key_added] = {}
    adata.uns[key_added]["params"] = dict(
        groupby=groupby,
        reference=reference,
        method=method,
        use_raw=use_raw,
        layer=layer,
        corr_method=corr_method,
    )

    # Initialize test object for statistical computations
    test_obj = _RankGenes(                                              # Test Object Initialization
        adata,
        groups_order,
        groupby,
        mask_var=mask_var,
        reference=reference,
        use_raw=use_raw,
        layer=layer,
        comp_pts=pts,
    )

    # Warn if raw count data is used without log-transformation
    if check_nonnegative_integers(test_obj.X) and method != "logreg":
        logg.warning(
            "It seems you use rank_genes_groups on the raw count data. "
            "Please logarithmize your data before calling rank_genes_groups."
        )

    # Determine the number of genes to rank, defaulting to all genes
    n_genes_user = n_genes
    if n_genes_user is None or n_genes_user > test_obj.X.shape[1]:
        n_genes_user = test_obj.X.shape[1]

    # Log group sizes
    logg.debug(f"consider {groupby!r} groups:")
    logg.debug(f"with sizes: {np.count_nonzero(test_obj.groups_masks_obs, axis=1)}")

    # Compute statistics for ranking genes
    test_obj.compute_statistics(                                               # compute_statistics helper function is used for statistical tests calculations
        method,
        corr_method=corr_method,
        n_genes_user=n_genes_user,
        rankby_abs=rankby_abs,
        tie_correct=tie_correct,
        **kwds,
    )

    # Store percentage of cells expressing each gene, if applicable
    if test_obj.pts is not None:
        groups_names = [str(name) for name in test_obj.groups_order]
        adata.uns[key_added]["pts"] = pd.DataFrame(
            test_obj.pts.T, index=test_obj.var_names, columns=groups_names
        )
    if test_obj.pts_rest is not None:
        adata.uns[key_added]["pts_rest"] = pd.DataFrame(
            test_obj.pts_rest.T, index=test_obj.var_names, columns=groups_names
        )

    # Adjust column levels in test statistics
    test_obj.stats.columns = test_obj.stats.columns.swaplevel()

    # Define data types for the results
    dtypes = {
        "names": "O",
        "scores": "float32",
        "logfoldchanges": "float32",
        "pvals": "float64",
        "pvals_adj": "float64",
    }

    # Save results to `.uns` in structured format
    for col in test_obj.stats.columns.levels[0]:
        adata.uns[key_added][col] = test_obj.stats[col].to_records(
            index=False, column_dtypes=dtypes[col]
        )

    # Log completion and summarize results added to `.uns`
    logg.info(
        "    finished",
        time=start,
        deep=(
            f"added to `.uns[{key_added!r}]`\n"
            "    'names', sorted np.recarray to be indexed by group ids\n"
            "    'scores', sorted np.recarray to be indexed by group ids\n"
            + (
                "    'logfoldchanges', sorted np.recarray to be indexed by group ids\n"
                "    'pvals', sorted np.recarray to be indexed by group ids\n"
                "    'pvals_adj', sorted np.recarray to be indexed by group ids"
                if method in {"t-test", "t-test_overestim_var", "wilcoxon"}
                else ""
            )
        ),
    )

    # Return the modified `adata` object or None if not copying
    return adata if copy else None

"""## 2) a) Statistical Tests

The rank_genes_groups function supports several statistical tests for evaluating differential expression, as specified by the method parameter. These tests include:

*   Logistic Regression (logreg),
*   T-Test (t-test)
*   Wilcoxon Rank-Sum Test (wilcoxon)
*   T-Test with Overestimated Variance (t-test_overestim_var)










"""

# Method Validation
if method not in (avail_methods := get_literal_vals(_Method)):
    raise ValueError(f"Method must be one of {avail_methods}.")

# Test Object Initialization
test_obj = _RankGenes(
    adata,
    groups_order,
    groupby,
    mask_var=mask_var,
    reference=reference,
    use_raw=use_raw,
    layer=layer,
    comp_pts=pts,
)

# Computing Statistics
test_obj.compute_statistics(
    method,
    corr_method=corr_method,
    n_genes_user=n_genes_user,
    rankby_abs=rankby_abs,
    tie_correct=tie_correct,
    **kwds,
)

"""## 2) b) Log2FoldChange(log2FC)

Log2 Fold Change is computed as:

log2FC = log
⁡
2
(
Mean Expression in Group A /
Mean Expression in Group B
)

Where:

*   Group A is the target group.
*   Group B is the reference group (or the rest of the data if no explicit reference is specified).
*   Mean Expression is typically computed as the average (or pseudocount-adjusted average for sparse data) of expression levels for a given gene.

To avoid issues with zeros in the denominator, a pseudocount (e.g., 1) is often added to both the numerator and denominator.
"""

def compute_statistics(
        self,
        method: _Method,
        *,
        corr_method: _CorrMethod = "benjamini-hochberg",
        n_genes_user: int | None = None,
        rankby_abs: bool = False,
        tie_correct: bool = False,
        **kwds,
    ) -> None:
        # Select the appropriate statistical test based on the specified method
        if method in {"t-test", "t-test_overestim_var"}:
            generate_test_results = self.t_test(method)  # Perform t-test
        elif method == "wilcoxon":
            generate_test_results = self.wilcoxon(tie_correct=tie_correct)  # Perform Wilcoxon test
        elif method == "logreg":
            generate_test_results = self.logreg(**kwds)  # Perform logistic regression

        # Initialize stats DataFrame to store test results
        self.stats = None
        n_genes = self.X.shape[1]  # Number of genes in the dataset

        # Iterate over each group and extract test results (scores and p-values)
        for group_index, scores, pvals in generate_test_results:
            group_name = str(self.groups_order[group_index])  # Group name for results

            # Select top-ranked genes if a limit is specified
            if n_genes_user is not None:
                scores_sort = np.abs(scores) if rankby_abs else scores  # Use absolute scores if rankby_abs is True
                global_indices = _select_top_n(scores_sort, n_genes_user)  # Get top N indices
                first_col = "names"  # First column stores gene names
            else:
                global_indices = slice(None)  # Include all genes if no limit is specified
                first_col = "scores"  # First column stores scores

            # Initialize stats DataFrame columns for the first group
            if self.stats is None:
                idx = pd.MultiIndex.from_tuples([(group_name, first_col)])
                self.stats = pd.DataFrame(columns=idx)

            # Add gene names to stats if selecting top genes
            if n_genes_user is not None:
                self.stats[group_name, "names"] = self.var_names[global_indices]

            # Add scores to the stats DataFrame
            self.stats[group_name, "scores"] = scores[global_indices]

            # Handle p-values if they are available
            if pvals is not None:
                self.stats[group_name, "pvals"] = pvals[global_indices]

                # Apply multiple testing correction to p-values
                if corr_method == "benjamini-hochberg":
                    from statsmodels.stats.multitest import multipletests

                    pvals[np.isnan(pvals)] = 1  # Replace NaN values with 1
                    _, pvals_adj, _, _ = multipletests(
                        pvals, alpha=0.05, method="fdr_bh"  # FDR correction
                    )
                elif corr_method == "bonferroni":
                    pvals_adj = np.minimum(pvals * n_genes, 1.0)  # Bonferroni correction
                self.stats[group_name, "pvals_adj"] = pvals_adj[global_indices]  # Add adjusted p-values

            # Calculate log fold changes if mean values are available
            if self.means is not None:
                mean_group = self.means[group_index]  # Mean expression in the group
                if self.ireference is None:
                    mean_rest = self.means_rest[group_index]  # Mean expression in the rest of the data
                else:
                    mean_rest = self.means[self.ireference]  # Mean expression in the reference group
                # Compute log2 fold changes with small value added to avoid division by zero
                foldchanges = (self.expm1_func(mean_group) + 1e-9) / (
                    self.expm1_func(mean_rest) + 1e-9
                )
                self.stats[group_name, "logfoldchanges"] = np.log2(
                    foldchanges[global_indices]
                )

        # Set the index of the stats DataFrame to gene names if no top-N selection is applied
        if n_genes_user is None:
            self.stats.index = self.var_names

"""## 2) c) P-values

Within the rank_gene_groups function, p-values are calculated depending on the statistical test specified by the method parameter (t-test, t-test_overestim_var, wilcoxon, or logreg).

Each method assumes certain properties about the data, and the function uses different test-specific routines to calculate the p-values.
"""

# Test Method Selection
if method in {"t-test", "t-test_overestim_var"}:
    generate_test_results = self.t_test(method)
elif method == "wilcoxon":
    generate_test_results = self.wilcoxon(tie_correct=tie_correct)
elif method == "logreg":
    generate_test_results = self.logreg(**kwds)

# Iterating over groups and extracting results
for group_index, scores, pvals in generate_test_results:
    ...
    if pvals is not None:
        self.stats[group_name, "pvals"] = pvals[global_indices]

"""## Assumptions of statistical tests

**1) T-Test (t-test or t-test_overestim_var)**

Code Line:  generate_test_results = self.t_test(method)

Assumptions:
*   The data follows a normal distribution.
*   The variance of gene expression across groups is either equal or overestimated (depending on the specific t-test variant).
*   Each gene is tested independently.

**2) Wilcoxon Rank-Sum Test (wilcoxon)**

Code Line: generate_test_results = self.wilcoxon(tie_correct=tie_correct)

Assumptions:
*   No assumptions about the distribution of the data.
*   Suitable for non-normally distributed data.
*   Ranks the data and compares medians across groups.

**3) Logistic Regression (logreg)**

Code Line:  generate_test_results = self.logreg(**kwds)

Assumptions:
*   Data is binary or can be modeled with a logistic function.
*   Assumes linear separability for marker identification.

## 2) d) Adjustment for Multiple Testing

After p-values are computed, they may be adjusted for multiple testing using correction methods:

1) Benjamini-Hochberg:
*   Controls the false discovery rate (FDR).
*   Suitable for large-scale testing with many genes.

2) Bonferroni:
*   Adjusts p-values by multiplying them by the number of tests.
*   Assumes independence of tests, leading to stricter correction.
"""

if corr_method == "benjamini-hochberg":
    from statsmodels.stats.multitest import multipletests
    pvals[np.isnan(pvals)] = 1
    _, pvals_adj, _, _ = multipletests(pvals, alpha=0.05, method="fdr_bh")
elif corr_method == "bonferroni":
    pvals_adj = np.minimum(pvals * n_genes, 1.0)
self.stats[group_name, "pvals_adj"] = pvals_adj[global_indices]

"""## 2) e) Group Comparison

The rank_gene_groups function distinguishes between conditions (or groups) primarily through the following:
*   **self.groups_order**: Identifies different conditions for each test.
*   **self.X**: Contains the gene expression data for all conditions.
*   **self.means and self.ireference**: Used for comparing the mean expression between conditions, especially when calculating fold-change.
*   **n_genes_user**: Allows for the selection of top-ranked genes based on specific criteria, such as fold change or p-values.
*   **generate_test_results**: Holds the results of statistical tests that are performed per condition to rank genes.
"""